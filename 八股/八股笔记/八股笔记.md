# JVM

## 堆内存分配

### 指针碰撞

一般情况下，JVM的对象都放在堆内存中（发生逃逸分析除外）。当类加载检查通过后，Java虚拟机开始为新生对象分配内存。如果Java堆中内存是绝对规整的，所有被使用过的的内存都被放到一边，空闲的内存放到另外一边，中间放着一个指针作为分界点的指示器，所分配内存仅仅是把那个指针向空闲空间方向挪动一段与对象大小相等的实例，这种分配方式就是 指针碰撞。

<img src="八股笔记.assets/image-20240411210811730.png" alt="image-20240411210811730" style="zoom: 67%;" />

### 空闲列表

如果Java堆内存中的内存并不是规整的，已被使用的内存和空闲的内存相互交错在一起，不可以进行指针碰撞啦，虚拟机必须维护一个列表，记录哪些内存是可用的，在分配的时候从列表找到一块大的空间分配给对象实例，并更新列表上的记录，这种分配方式就是空闲列表。

### TLAB

## 垃圾回收器

### 类型

#### 新生代收集器

- Serial收集器：复制算法，单线程收集器，标记和清理都是单线程，优点是简单高效
- ParNew收集器：复制算法，并行收集器，实际上是Serial收集器的多线程版
- Parallel Scavenge收集器：复制算法，并行收集器，追求高吞吐量，高效利用 CPU

#### 老年代收集器

- Serial Old收集器：复制算法，单线程收集器
- Parallel Old收集器 ：标记-整理算法，并行收集器，吞吐量优先，Parallel Scavenge收集器的老年代版本
- CMS(Concurrent Mark Sweep)收集器：标记-清除算法，并行收集器，以获取**最短回收停顿时间**为目标的收集器，具有高并发、低停顿的特点，追求最短GC回收停顿时间

#### 整堆收集器

- G1(Garbage First)收集器：标记-整理算法，不会产生内存碎片，回收的范围是**整个Java堆**

### 如何选择

# 多线程和并发

## 线程的定义

### 线程的状态

线程通常都有五种状态，创建、就绪、运行、阻塞和死亡。

1. **创建状态。**在生成线程对象，并没有调用该对象的start方法，这是线程处于创建状态。
2. **就绪状态。**当调用了线程对象的start方法之后，该线程就进入了就绪状态，但是此时线程调度程序还没有把该线程设置为当前线程，此时处于就绪状态。在线程运行之后，从等待或者睡眠中回来之后，也会处于就绪状态。
3. **运行状态。**线程调度程序将处于就绪状态的线程设置为当前线程，此时线程就进入了运行状态，开始运行run函数当中的代码。
4. **阻塞状态。**线程正在运行的时候，被暂停，通常是为了等待某个事件的发生(比如说某项资源就绪)之后再继续运行。sleep，suspend，wait等方法都可以导致线程阻塞。
5. **死亡状态。**如果一个线程的run方法执行结束或者调用stop方法后，该线程就会死亡。对于已经死亡的线程，无法再使用start方法令其进入就绪。

## 线程的使用

### 创建线程

严格来说，Java 就只有一种方式可以创建线程，那就是通过`new Thread().start()`创建。

### 实现多线程的方法

1. 继承Thread类

   ```java
   public class ExtendsThread extends Thread {
       @Override
       public void run() {
           System.out.println("1......");
       }
   
       public static void main(String[] args) {
           new ExtendsThread().start();
       }
   }
   ```

   

2. 实现Runnable接口

3. 实现Callable接口

4. 线程池方式创建

5. 使用`CompletableFuture`类

### 线程阻塞

#### CountDownLatch

##### CountDownLatch有什么用

CountDownLatch 允许一个或多个线程**等待**直到在其他线程中一组操作执行完成。

##### CountDownLatch 的原理是什么

CountDownLatch 是共享锁的一种实现，它默认构造 AQS 的 state 值为 count。当线程使用 `countDown() `方法时,其实使用了tryReleaseShared方法以 CAS 的操作来减少 state，直至 state 为 0 。当调用 await() 方法的时候，如果 state 不为 0，那就证明任务还没有执行完毕，`await()` 方法就会一直阻塞，也就是说 await() 方法之后的语句不会被执行。直到count 个线程调用了countDown()使 state 值被减为 0，或者调用await()的线程被中断，该线程才会从阻塞中被唤醒，await() 方法之后的语句得到执行。

#### CyclicBarrier

##### CyclicBarrier有什么用

CyclicBarrier也可以实现线程间的技术等待，但是它的功能比 CountDownLatch 更加复杂和强大。

##### CyclicBarrier的原理是什么

CyclicBarrier 内部通过一个 count 变量作为计数器，count 的初始值为 parties 属性的初始化值，每当一个线程到了栅栏这里了，那么就将计数器减 1。如果 count 值为 0 了，表示这是这一代最后一个线程到达栅栏，就尝试执行我们构造方法中输入的任务。

##### CyclicBarrier和CountDownLatch的区别

- CyclicBarrier可以**重用**，CountDownLatch **不可重用**
- CyclicBarrier的某个线程运行到某个点上之后，该**线程即停止运行**，直到所有的线程都到达了这个点，所有线程才重新运行；CountDownLatch则不是，某线程运行到某个点上之后，只是给某个数值-1而已，该线程**继续运行**
- CyclicBarrier只能唤起一个任务，CountDownLatch可以唤起多个任务

### 线程切换

#### 多线程中的上下文切换是什么

在多线程环境下，当CPU需要切换执行不同的线程时，需要保存当前线程的执行状态以及程序计数器等相关信息，并恢复下一个线程的执行状态，这个过程就是上下文切换。 上下文是指线程的当前执行环境，保存在**进程控制块**中，包括寄存器的值、程序计数器（PC）的值、栈指针、堆栈的内容、线程的状态等。

发生上下文切换的情况：中断处理，多任务处理，用户态切换。

### 函数

#### start() 和 run() 方法有什么区别？

- start() 用来启动线程，使线程处于**就绪状态**，start() 方法内部回调用run()
- 调用run()方法的时候，只会是在原来的线程中调用，没有新的线程启动

#### sleep() 方法和 wait() 方法对比

- sleep() 方法没有释放锁，而 wait() 方法释放了锁 。
- sleep() 通常被用于暂停执行，wait() 通常被用于线程间交互/通信。
- sleep() 方法执行完成后，线程会自动苏醒，或者也可以使用 `wait(long timeout)` 超时后线程会自动苏醒。wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。
- sleep() 是 `Thread` 类的静态本地方法，wait() 则是 `Object` 类的本地方法。

#### notify()和notifyAll()有什么区别

**notify() 方法**：

- notify() 方法是 `Object` 类的一个方法，用于唤醒因调用 wait() 方法而处于**等待状态的一个线程**。如果有多个线程在等待，那么只有一个线程会被唤醒。具体唤醒哪一个线程是不确定的，取决于线程**调度器的策略**。

**notifyAll() 方法**：

- notifyAll() 方法是 `Object` 类的一个方法，用于唤醒因调用 wait( ) 方法而处于**等待状态的所有线程**，可以确保所有等待的线程都有机会竞争锁。

#### wait()、sleep()、join()和yield()的区别

- sleep() ：转入阻塞状态，休眠并释放cpu
- wait() ：必须放在**循环体和同步代码块**中，执行该方法的线程会**释放锁**，进入线程等待池中等待被再次**唤醒**
- yield() ：转入就绪状态，给相同优先级或更高优先级的线程运行的机会
- join() ：当前线程进入阻塞状态直到另一个线程运行结束等待该线程终止。如：t.join(); //用于等待 t 线程运行结束

## 线程安全

### 多线程的问题

内存泄漏、死锁、线程不安全等

### 死锁

#### 死锁条件

1. **互斥条件：**该资源任意一个时刻只由一个线程占用。
2. **请求与保持条件：**一个线程因请求资源而阻塞时，对已获得的资源保持不放。
3. **不剥夺条件：**线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
4. **循环等待条件：**若干线程之间形成一种头尾相接的循环等待资源关系。

#### 破坏死锁

- **破坏请求与保持条件**：一次性申请所有的资源。
- **破坏不剥夺条件**：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。
- **破坏循环等待条件**：按顺序申请锁

## ThreadLocal

### ThreadLocal 有什么用

实现每一个线程都有自己的**专属本地变量**。可以理解为线程本地变量，他会在每个线程都创建一个副本，那么在线程之间访问内部
副本变量就行了，做到了线程之间互相隔离，用空间换时间。

### ThreadLocal的原理

ThreadLocal有一个静态内部类ThreadLocalMap，而ThreadLocalMap 可以存储以ThreadLocal 为 key ，Object 对象为 value 的键值对。

### ThreadLocal 内存泄露问题是怎么导致的

ThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用，而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉，就会存在内存泄露的问题，即ThreadLocalMap中就存在key为null，但是value有值的entry对象，value永远无法被GC回收。

ThreadLocalMap 实现中已经考虑了这种情况，在调用 `set()`、`get()`、`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后最好手动调用`remove()`方法。

### 引用类型有哪些

强引用 > 软引用 > 弱引用 > 虚引用

1. **强引用**关联的对象，永远不会被GC回收。
2. 系统在发生内存溢出前会对**软引用**的对象进行回收。
3. **弱引用**的对象下一次GC的时候一定会被回收，而不管内存是否足够。
4. **虚引用**必须和ReferenceQueue一起使用，同样的当发生GC的时候，虚引用也会被回收。

## 线程池

### 什么是线程池

线程池就是管理一系列线程的资源池。使用线程池的**好处**：

- **降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
- **提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。
- **提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

### 如何创建线程池

1. 通过`ThreadPoolExecutor`构造函数来创建（推荐）
2. 通过 `Executor` 框架的工具类 `Executors` 来创建（四种线程池类型）

### 线程池的核心参数

- `corePoolSize` : 任务队列未达到队列容量时，最大可以同时运行的线程数量。
- `maximumPoolSize` : 任务队列中存放的任务达到队列容量的时候，当前可以同时运行的线程数量变为最大线程数。
- `workQueue`: 新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。
- `keepAliveTime`：线程池中的线程数量大于核心线程数的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了 活跃时间才会被回收销毁。
- `handler`：拒绝策略

### 线程池处理任务的流程

1. 如果当前运行的线程数小于核心线程数，那么就会新建一个线程来执行任务。
2. 如果当前运行的线程数等于或大于核心线程数，但是小于最大线程数，那么就把该任务放入到任务队列里等待执行。
3. 如果向任务队列投放任务失败（任务队列已经满了），但是当前运行的线程数是小于最大线程数的，就新建一个线程来执行任务。
4. 如果当前运行的线程数已经等同于最大线程数了，新建线程将会使当前运行的线程超出最大线程数，那么当前任务会被拒绝，并根据拒绝策略处理。

### 线程池的拒绝策略有哪些

1. AbortPolicy：直接丢弃任务，抛出异常，这是默认策略
2. CallerRunsPolicy：只用调用者所在的线程来处理任务
3. DiscardOldestPolicy：丢弃等待队列中最旧的任务，并执行当前任务
4. DiscardPolicy：直接丢弃任务，也不抛出异常

### 线程池的类型

- **FixedThreadPool：**固定线程数量的线程池。
- SingleThreadExecutor： 只有一个线程的线程池。
- **CachedThreadPool：** 可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行**复用**。
- **ScheduledThreadPool：**给定的延迟后运行任务或者定期执行任务的线程池。

### 如何设定线程池大小

判断要执行的任务类型是什么，如果是**CPU密集型任务**，可以将线程数设置为 $CPU 核心数+1$；如果是**I/O 密集型任务**，可以将线程数设置为 $2 * CPU 核心数$

### 如何设计一个能够根据任务的优先级来执行的线程池

可以考虑使用 `PriorityBlockingQueue` （优先级阻塞队列）作为任务队列（ThreadPoolExecutor 的构造函数有一个 `workQueue` 参数可以传入任务队列）。

PriorityBlockingQueue 是一个支持优先级的无界阻塞队列，可以看作是线程安全的 PriorityQueue，两者底层都是使用**小顶堆形式**的二叉堆，即值最小的元素优先出队。不过，PriorityQueue 不支持阻塞操作。

要想让 PriorityBlockingQueue 实现对任务的排序，传入其中的任务必须是具备排序能力的，方式有两种：

1. 提交到线程池的任务**实现 Comparable 接口**，并重写 compareTo 方法来指定任务之间的优先级比较规则。
2. 创建 PriorityBlockingQueue 时传入一个 **Comparator 对象**来指定任务之间的排序规则(推荐)。

## Future

### Future类有什么用

Future是异步思想的典型运用，可以将耗时任务交给一个子线程去异步执行，等其他事情干完后，通过 Future 类获取到耗时任务的执行结果。

### Callable 和 Future 有什么关系

FutureTask 提供了 Future 接口的基本实现，可传入 Callable 或者 Runnable 对象。FutureTask 相当于对Callable  进行了封装，管理着任务执行的情况，存储了 Callable 的 call 方法的任务执行结果。

## 锁

### 锁的分类

#### 重量级锁

synchronized

- 重量级锁为什么效率低？

  在 Java 早期版本中，监视器锁（monitor）是依赖于底层的操作系统的 `Mutex Lock` 来实现的，Java 的线程是映射到操作系统的原生线程之上的。如果要**挂起或唤醒**一个线程，都需要操作系统帮忙完成，而操作系统实现**线程之间的切换**时需要从**用户态转换到内核态**，这个状态之间的转换需要相对比较长的时间，时间成本相对较高。

#### 轻量级锁

volatile

### volatile

如果我们将变量声明为 `volatile` ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取，具备了两层语义：

1. `volatile` 关键字可以保证变量的可见性
2. 防止 JVM 的指令重排序，通过插入特定的 **内存屏障** 的方式来禁止指令重排序。

<img src="八股笔记.assets/jmm2.png" alt="JMM(Java 内存模型)强制在主存中进行读取" style="zoom:67%;" />

<center>JMM(Java 内存模型)强制在主存中进行读取</center>

#### 双重校验锁实现单例模式

单例模式：在多线程的情况下，如果有两个线程同时调用getInstance()，可能导致**对象被实例化了两次并且被不用对象持有**，违背了单例模式

- **解决：双重校验锁**

```java
public class Singleton {
    private volatile static Singleton uniqueSingleton;
    private Singleton() {
    }
    public Singleton getInstance() {
        if (null == uniqueSingleton) {
            synchronized (Singleton.class) {
                if (null == uniqueSingleton) {
                    uniqueSingleton = new Singleton();
                }
            }
        }
        return uniqueSingleton;
    }
}
```

- **分析**

对象实例化的过程：

1. 分配内存空间
2. 初始化对象
3. 将对象指向刚分配的内存空间

如果未使用volatile，可能会导致指令重排（2,3发生变化），导致其他线程读到未被初始化的对象。使用了volatile关键字后，重排序被禁止，所有的写（write）操作都将发生在读（read）操作之前。

参考：https://www.cnblogs.com/xz816111/p/8470048.html

#### volatile 可以保证原子性么

`volatile` 关键字能保证变量的可见性，但不能保证对变量的操作是原子性的。

**原子操作** 即最小不可拆分的操作，也就是说操作一旦开始，就不能被打断，直到操作完成。

### synchronized

#### synchronized的使用范围

1. 修饰实例方法（锁当前对象实例）
2. 修饰静态方法（锁当前对象实例）
3. 修饰代码块（锁指定对象/类）

#### 可以用synchronized(String a)上锁吗

尽量不要使用 `synchronized(String a)` ，因为 JVM 中，字符串常量池具有**缓存功能**，即**相同的字符串常量在内存中只会被存储一份**。因此，如果多个线程分别使用相同的字符串常量作为锁对象，那么它们实际上会锁定同一个对象，从而可能引发**不必要的竞争**和性能问题。

#### 构造方法可以用 synchronized 修饰么

**不能**。构造方法本身就属于线程安全的，不存在同步的构造方法一说。

#### synchronized 和 volatile 有什么区别？

- volatile 关键字是线程同步的**轻量级**实现，所以 volatile 性能比synchronized（**重量级**）关键字要好 。
- volatile 关键字只能用于**变量**，而 synchronized 关键字可以修饰**方法以及代码块** 。
- volatile 关键字能保证数据的**可见性**，但不能保证数据的**原子性**。synchronized 关键字**两者**都能保证。
- volatile 关键字主要用于解决变量在多个线程之间的**可见性**，而synchronized 关键字解决的是多个线程之间访问资源的**同步性**。

#### synchronized的底层

1. **同步语句块**

使用 `monitorenter` 和 `monitorexit` 指令，其中 monitorenter 指令指向同步代码块的**开始**位置，monitorexit 令则指明同步代码块的**结束**位置。

**执行过程：**

当执行 `monitorenter` 指令时，线程试图获取锁也就是获取 **对象监视器 `monitor`** 的持有权。在执行`monitorenter`时，会尝试获取对象的锁，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 。对象锁的的拥有者线程才可以执行 `monitorexit` 指令来释放锁。在执行 `monitorexit` 指令后，将锁计数器设为 0，表明锁被释放，其他线程可以尝试获取锁。如果获取对象锁失败，那当前线程就要阻塞等待，直到锁被另外一个线程释放为止。

<img src="八股笔记.assets/image-20240415195021083.png" alt="image-20240415195021083" style="zoom:80%;" />

2. **修饰方法**

使用`ACC_SYNCHRONIZED` 标识，该标识指明了该方法是一个同步方法。JVM 通过该 `ACC_SYNCHRONIZED` 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。如果是实例方法，JVM 会尝试获取实例对象的锁。如果是静态方法，JVM 会尝试获取当前 class 的锁。

### 乐观锁和悲观锁

#### 什么是悲观锁

总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以**每次在拿数据的时候都会上锁**，这样别人想拿这个数据就会阻塞直到它拿到锁。也就是说，**共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程**。

- **悲观锁举例**：

数据库中的锁机制：行锁，表锁等，读锁，写锁等、synchronized、ReentrantLock锁。

- **悲观锁缺点：**

1. **增加性能开销。**高并发的场景下，激烈的锁竞争会造成线程阻塞，大量阻塞线程会导致系统的上下文切换，增加系统的性能开销。

2. **导致死锁。**

#### 什么是乐观锁

乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在**提交修改**的时候去验证对应的资源（也就是数据）是否被其它线程修改了。

- **乐观锁缺点：**

如果冲突频繁发生（**写占比非常多**的情况），会频繁失败和重试，这样同样会非常影响性能，导致 CPU 飙升。

#### 如何实现乐观锁

- **使用版本号机制**

  要更新数据值时，在读取数据的同时也会读取版本号，在提交更新时，若刚才**读取到的版本号为当前数据库中的版本号值相等**时才更新，否则采取**丢弃或再次尝试**的策略。

- **CAS 算法实现**（ **Compare And Swap**）

  - **CAS 涉及到三个操作数：**

    - **V**：要更新的变量值(Var)
    - **E**：预期值(Expected)
    - **N**：拟写入的新值(New)

    当且仅当 **V == E** 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程被告知失败，允许**再次尝试或放弃**。

    CAS 的具体实现和操作系统以及 CPU 都有关系。`sun.misc`包下的`Unsafe`类提供了`compareAndSwapObject`、`compareAndSwapInt`、`compareAndSwapLong`方法来实现的对`Object`、`int`、`long`类型的 CAS 操作

  - **CAS 存在的问题：**

    - **ABA问题**：一个变量 V 初次读取的时候是 A 值，并且在准备赋值的时候检查到它仍然是 A 值，有可能该值被其他线程修改过，又修改回来了。

      解决思路：加上**版本号或者时间戳**，如JDK 1.5 以后的 `AtomicStampedReference` 类，其中的 `compareAndSet()` 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。

    - **循环时间长开销大：**CAS 经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功。如果长时间不成功，会给 CPU 带来非常大的执行开销。

    - **只能保证一个共享变量的原子操作**

      解决思路：从 JDK 1.5 开始，提供了`AtomicReference`类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作

#### 乐观锁和悲观锁的使用场景

- 悲观锁通常多用于写比较多的情况（多写场景，竞争激烈），这样可以避免频繁失败和重试影响性能，悲观锁的开销是固定的。不过，如果乐观锁解决了频繁失败和重试这个问题的话（比如`LongAdder`），也是可以考虑使用乐观锁的，要视实际情况而定。

- 乐观锁通常多用于写比较少的情况（多读场景，竞争较少），这样可以避免频繁加锁影响性能。不过，乐观锁主要针对的对象是单个共享变量（参考`java.util.concurrent.atomic`包下面的原子变量类）。

### ReentrantLock

#### ReentrantLock的原理

ReentrantLock 实现了 `Lock` 接口，是一个可重入且独占式的锁。ReentrantLock 更灵活、更强大，增加了轮询、超时、中断、公平锁和非公平锁等高级功能。ReentrantLock 里面有一个内部类 `Sync`，Sync 继承 **AQS**，添加锁和释放锁的大部分操作实际上都是在Sync 中实现的。Sync  有**公平锁** FairSync 和**非公平锁** NonfairSync 两个子类，默认使用非公平锁。

#### 什么叫可重入锁

**可重入锁** 也叫**递归锁**，指的是线程可以**再次获取**自己的内部锁。

以 ReentrantLock 为例，`state` 初始值为 0，表示未锁定状态。A 线程 `lock()` 时，会调用 tryAcquire() 独占该锁并将 state+1 。此后，其他线程再 tryAcquire() 时就会失败，直到 A 线程 `unlock()` 到 state=0（即释放锁）为止，其它线程才有机会获取该锁。当然，释放锁之前，A 线程自己是可以重复获取此锁的（state 会累加），这就是可重入的概念。但要注意，**获取多少次就要释放多少次，这样才能保证 state 是能回到零态的。**

#### 公平锁和非公平锁有什么区别

**公平锁** : 锁被释放之后，先申请的线程先得到锁。性能较差一些，保证时间上的绝对顺序，上下文切换更频繁。

**非公平锁**：锁被释放之后，后申请的线程可能会先获取到锁，是随机或者按照其他优先级排序的。性能更好，但某些线程可能永远无法获取到锁。

#### synchronized 和 ReentrantLock 有什么区别

**相似点：**

加锁方式同步，而且都是阻塞式的同步（进行线程阻塞和唤醒的代价是比较高的）

**区别：**

1. **synchronized 依赖于 JVM 而 ReentrantLock 依赖于 API**

   synchronized 是依赖于 JVM 实现的，对synchronized 的优化都是在虚拟机层面实现的，并没有直接暴露给我们。

   ReentrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock() 方法配合 try/finally 语句块来完成），可以直接查看它的源代码，来看它是如何实现的。

2. **ReentrantLock 比 synchronized 增加了一些高级功能**
   - **等待可中断：**持有锁的线程长期不释放的时候，正在等待的线程可以选择放弃等待，对Synchronized来说可以避免出现死锁的情况。
   - **可实现公平锁：**ReentrantLock默认的构造函数是创建的非公平锁，可以通过参数true设为公平锁。
   - **可实现选择性通知**：用ReentrantLock类结合`Condition`实例可以实现选择性的进行线程通知（通知**部分线程**），而synchronized 会通知**所有线程。**

#### 可中断锁和不可中断锁有什么区别

**可中断锁**：获取锁的过程中可以被中断，不需要一直等到获取锁之后 才能进行其他逻辑处理。`ReentrantLock` 就属于是可中断锁。

**不可中断锁**：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。 `synchronized` 就属于是不可中断锁。

#### ReentrantReadWriteLock 是什么

ReentrantReadWriteLock 实现了 `ReadWriteLock` ，是一个可重入的读写锁，既可以保证多个线程同时读的效率，同时又可以保证有写入操作时的线程安全。**读锁是共享锁，写锁是独占锁。**读锁可以被同时读，可以同时被多个线程持有，而写锁最多只能同时被一个线程持有。

#### StampedLock 是什么

StampedLock 是 JDK 1.8 引入的性能更好的读写锁，不可重入且不支持条件变量 `Condition`。不同于一般的 Lock 类，StampedLock 并不是直接实现 Lock或 ReadWriteLock接口，而是基于 **CLH 锁** 独立实现

### Semaphore

#### Semaphore有什么用

Semaphore(信号量)可以用来控制同时访问特定资源的线程数量。通过两个函数实现：

```java
// 初始共享资源数量
final Semaphore semaphore = new Semaphore(5);
// 获取1个许可
semaphore.acquire();
// 释放1个许可
semaphore.release();
```

Semaphore 有两种模式：。

- **公平模式：** 调用 `acquire()` 方法的顺序就是获取许可证的顺序，遵循 FIFO；
- **非公平模式：** 抢占式的。

**使用场景：**

​		通常用于那些资源有明确访问数量限制的场景比如**限流**

#### Semaphore的原理

Semaphore 是共享锁的一种实现，它默认构造 AQS 的 `state` 值为 permits，你可以将 permits`的值理解为**许可证的数量**，只有拿到许可证的线程才能执行。

- **semaphore.acquire()**

  线程尝试获取许可证，如果 `state >= 0` 的话，则表示可以获取成功。如果获取成功的话，使用 CAS 操作去修改 state 的值 state=state-1。如果 `state<0` 的话，则表示许可证数量不足。此时会创建一个 Node 节点加入阻塞队列，挂起当前线程。

- **semaphore.release();**

  线程尝试释放许可证，并使用 CAS 操作去修改 state 的值 `state=state+1`。释放许可证成功之后，同时会唤醒同步队列中的一个线程。被唤醒的线程会重新尝试去修改 state 的值 `state=state-1` ，如果 `state>=0` 则获取令牌成功，否则重新进入阻塞队列，挂起线程。

### AQS

#### AQS是什么

抽象队列同步器，全称为 `AbstractQueuedSynchronizer`，是一个抽象类，主要用来构建锁和同步器。

#### AQS的原理

1. 同步状态

   使用由volatile 修饰的成员变量 `state`，来展示当前临界资源的获锁情况。如果被请求的共享资源**空闲**，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。

2. 线程等待队列

   使用 **CLH 队列锁**，来应对被请求的共享资源**被占用**的情况，将暂时获取不到锁的线程加入到队列中。

   **CLH队列**是一个虚拟的**双向队列**。AQS 是将每条请求共享资源的线程封装成一个 CLH 锁队列的一个结点来实现锁的分配。在 CLH 同步队列中，一个节点表示一个线程，它保存着线程的引用、 当前节点在队列中的状态、前驱节点、后继节点。

<img src="八股笔记.assets/CLH.png" alt="img" style="zoom:67%;" />

# Mysql

## 存储引擎

### Mysql有哪些引擎

- MYISAM：全表锁，拥有较高的执行速度，不支持事务，不支持外键，并发性能差，占用空间相对较小，对事务完整性没有要求，以select、insert为主的应用基本上可以使用这引擎
- **Innodb：**行级锁，提供了具有提交、回滚和崩溃回复能力的事务安全，支持自动增长列，支持外键约束，并发能力强，占用空间是MYISAM的2.5倍，处理效率相对会差一些
- Memory：全表锁，存储在内存中，速度快，但会占用和数据量成正比的内存空间且数据在mysql重启时会丢失，默认使用HASH索引，检索效率非常高，但不适用于精确查找，主要用于那些内容变化不频繁的代码表
- MERGE：是一组MYISAM表的组合

### InnoDB与MyISAM的区别

1. InnoDB支持事务，MyISAM不支持。
2. InnoDB支持外键，而MyISAM不支持。
3. InnoDB是**聚集索引**，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高。而MyISAM是**非聚集索引**，数据文件是分离的，索引保存的是数据文件的指针。
4. InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量**保存了整个表的行数**，执行上述语句时只需要读出该变量即可，速度很快；

## 索引

### 索引的分类

- 按「数据结构」分类：**B+tree索引、Hash索引、Full-text索引**。
- 按「物理存储」分类：**聚簇索引（主键索引）、二级索引（辅助索引）**。
- 按「字段特性」分类：**主键索引、唯一索引、普通索引、前缀索引**。
- 按「字段个数」分类：**单列索引、联合索引**。

### InnoDb如何选择列作为索引

- 如果有**主键**，默认会使用主键作为聚簇索引的索引键（key）；
- 如果没有主键，就选择第一个**不包含 NULL 值的唯一列**作为聚簇索引的索引键（key）；
- 在上面两个都没有的情况下，InnoDB 将自动生成一个**隐式自增 id 列**作为聚簇索引的索引键（key）；

### B+树

#### 主键索引的B+树

B+Tree 是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，而且每个节点里的数据是**按主键顺序存放**的。每一层父节点的索引值都会出现在下层子节点的索引值中，因此在叶子节点中，包括了所有的索引值信息，并且每一个叶子节点都有两个指针，分别指向下一个叶子节点和上一个叶子节点，形成一个**双向链表**。

<img src="八股笔记.assets/btree.drawio.png" alt="主键索引 B+Tree" style="zoom: 67%;" />

- **B+树的优点：**

  B+Tree 存储千万级的数据只需要 **3-4 层高度**就可以满足，数据库的索引和数据都是存储在硬盘的，我们可以把**读取一个节点当作一次磁盘 I/O 操作，**这意味着从千万级的表查询目标数据最多需要 3-4 次磁盘 I/O，所以B+Tree 相比于 B 树和二叉树来说，最大的优势在于查询效率很高，因为即使在数据量很大的情况，查询一个数据的磁盘 I/O 依然维持在 3-4次。

#### 二级索引的B+树

**区别：**

- 主键索引的 B+Tree 的叶子节点存放的是实际的**完整数据**；
- 二级索引的 B+Tree 的叶子节点存放的是**主键值**，而不是实际数据。

<img src="八股笔记.assets/二级索引btree.drawio.png" alt="二级索引 B+Tree" style="zoom:67%;" />

**索引过程：回表**

会先检二级索引中的 B+Tree 的索引值，找到对应的叶子节点，然后获取主键值，然后再通过主键索引中的 B+Tree 树查询到对应的叶子节点，然后获取整行数据。

#### 什么是索引覆盖

在二级索引的B+
